{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CZAgQ254GanPkcqta1_tpJRnugxQktPZ",
      "authorship_tag": "ABX9TyOXUkj7vaJGcYVBsX40DSSX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danh1905/Scalable-Project/blob/main/scalableProj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03d91343"
      },
      "source": [
        "To upload a file from your local system, you can use `google.colab.files.upload()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "f693bc95",
        "outputId": "6fa7d2f7-ca15-43e1-8718-c2d6041ac711"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2fb1b54f-20b0-4edf-87b7-6c52fc1cde75\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2fb1b54f-20b0-4edf-87b7-6c52fc1cde75\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Customer-Churn-Prediction.csv to Customer-Churn-Prediction.csv\n",
            "User uploaded file \"Customer-Churn-Prediction.csv\" with length 977501 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install pyspark\n"
      ],
      "metadata": {
        "id": "qIIliu1TREQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark py4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-SXRE2BQ8cu",
        "outputId": "04942355-4fa2-4514-de04-73a1ab439442"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (0.10.9.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Read CSV\").getOrCreate()\n",
        "churn_rate = spark.read.csv(\"/content/Customer-Churn-Prediction.csv\", header=True, inferSchema=True)\n",
        "churn_rate.printSchema()\n"
      ],
      "metadata": {
        "id": "05wH-rwERrcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d59548-eff2-439e-93e8-325a653b50b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "40WSlIWnCMIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.sql.functions import col, sum, when, trim, lit\n",
        "\n",
        "#Drop the useless ID\n",
        "churn_rate = churn_rate.drop(\"customerID\")\n",
        "\n",
        "# Fix TotalCharges (Convert String to Number)\n",
        "# Replace empty strings with nulls first, then cast to Double, and fill actual nulls with 0\n",
        "churn_rate = churn_rate.withColumn(\"TotalCharges\",\n",
        "                                   when(trim(col(\"TotalCharges\")) == \"\", lit(None)).otherwise(col(\"TotalCharges\")))\n",
        "churn_rate = churn_rate.withColumn(\"TotalCharges\", col(\"TotalCharges\").cast(DoubleType()))\n",
        "churn_rate = churn_rate.fillna(0, subset=[\"TotalCharges\"])\n",
        "\n",
        "# Check null values\n",
        "def count_nulls(churn_rate):\n",
        "    null_counts = churn_rate.select([\n",
        "        sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
        "        for c in churn_rate.columns\n",
        "    ])\n",
        "    return null_counts\n",
        "\n",
        "null_churn_rate = count_nulls(churn_rate)\n",
        "null_churn_rate.show()"
      ],
      "metadata": {
        "id": "b2Nns7UqAFbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251ae56e-b367-445c-fcc9-d4aa48d5f580"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|Contract|PaperlessBilling|PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
            "+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "|     0|            0|      0|         0|     0|           0|            0|              0|             0|           0|               0|          0|          0|              0|       0|               0|            0|             0|           0|    0|\n",
            "+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENCODE ALL TEXT COLUMNS\n",
        "\n",
        "# List of columns that are text (categorical) and need to be numbers\n",
        "# Note: I excluded 'Churn' because we handle it separately as the label\n",
        "categorical_cols = [\n",
        "    \"gender\", \"Partner\", \"Dependents\", \"PhoneService\", \"MultipleLines\",\n",
        "    \"InternetService\", \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
        "    \"TechSupport\", \"StreamingTV\", \"StreamingMovies\", \"Contract\",\n",
        "    \"PaperlessBilling\", \"PaymentMethod\"\n",
        "]\n",
        "\n",
        "# This loop converts each text column into a number column\n",
        "# Example: \"gender\" becomes \"gender_index\" (0 or 1)\n",
        "indexers = []\n",
        "for column in categorical_cols:\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=column + \"_index\")\n",
        "    churn_rate = indexer.fit(churn_rate).transform(churn_rate)\n",
        "\n",
        "# Don't forget to encode the Target variable (Churn) too!\n",
        "label_indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\")\n",
        "churn_rate = label_indexer.fit(churn_rate).transform(churn_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "KAev-9IkKplw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ASSEMBLE\n",
        "\n",
        "# Gather all the NEW numbered columns + the original numerical columns\n",
        "input_features = [c + \"_index\" for c in categorical_cols] + \\\n",
        "                 [\"SeniorCitizen\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "\n",
        "# Squash them into one vector\n",
        "assembler = VectorAssembler(inputCols=input_features, outputCol=\"features\")\n",
        "final_data = assembler.transform(churn_rate)\n",
        "\n",
        "# Show the result\n",
        "final_data.select(\"features\", \"label\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L_KoGyvK4PM",
        "outputId": "32e73f8e-c5b6-4e46-bafc-75e749600059"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(19,[0,1,3,4,5,7,...|  0.0|\n",
            "|(19,[5,6,8,12,13,...|  0.0|\n",
            "|(19,[5,6,7,14,16,...|  1.0|\n",
            "|[0.0,0.0,0.0,1.0,...|  0.0|\n",
            "|(19,[0,16,17,18],...|  1.0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "# SCALE THE FEATURES\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\",\n",
        "                        withStd=True, withMean=False)\n",
        "\n",
        "# Compute the scaling statistics\n",
        "scalerModel = scaler.fit(final_data)\n",
        "\n",
        "# Apply the scaling\n",
        "data_ready = scalerModel.transform(final_data)\n",
        "\n",
        "# Show the difference\n",
        "data_ready.select(\"features\", \"scaled_features\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtJXAwlLLpvb",
        "outputId": "a48c7c64-8cb5-4be3-a090-56133941a4cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|features                                                                           |scaled_features                                                                                                                                                                                                                                                |\n",
            "+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|(19,[0,1,3,4,5,7,16,17,18],[1.0,1.0,1.0,2.0,1.0,1.0,1.0,29.85,29.85])              |(19,[0,1,3,4,5,7,16,17,18],[1.9999485067372065,2.0010104673844156,3.3812086352456543,3.0485990271781893,1.283900316116114,1.2845683936851353,0.04071788746400118,0.9920223754752117,0.013168375165523978])                                                     |\n",
            "|(19,[5,6,8,12,13,14,16,17,18],[1.0,1.0,1.0,2.0,1.0,1.0,34.0,56.95,1889.5])         |(19,[5,6,8,12,13,14,16,17,18],[1.283900316116114,1.2548861854587148,1.2839836194317378,2.493941649067479,2.0347663265386586,0.8703925469441071,1.38440817377604,1.8926524048011157,0.8335559422196835])                                                        |\n",
            "|(19,[5,6,7,14,16,17,18],[1.0,1.0,1.0,1.0,2.0,53.85,108.15])                        |(19,[5,6,7,14,16,17,18],[1.283900316116114,1.2548861854587148,1.2845683936851353,0.8703925469441071,0.08143577492800236,1.7896283055055324,0.04771054519770245])                                                                                               |\n",
            "|[0.0,0.0,0.0,1.0,2.0,1.0,1.0,0.0,1.0,1.0,0.0,0.0,2.0,1.0,2.0,0.0,45.0,42.3,1840.75]|[0.0,0.0,0.0,3.3812086352456543,3.0485990271781893,1.283900316116114,1.2548861854587148,0.0,1.2839836194317378,1.2564449803233473,0.0,0.0,2.493941649067479,2.0347663265386586,1.7407850938882141,0.0,1.8323049358800532,1.4057804516784405,0.8120498018739786]|\n",
            "|(19,[0,16,17,18],[1.0,2.0,70.7,151.65])                                            |(19,[0,16,17,18],[1.9999485067372065,0.08143577492800236,2.349614135547654,0.06690063966002383])                                                                                                                                                               |\n",
            "+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data"
      ],
      "metadata": {
        "id": "zGlgcNrZ39YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "oDpXCm9D61AP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# STEP 5: SPLIT DATA\n",
        "\n",
        "#80% (train) & 20% (test)\n",
        "train_data, test_data = data_ready.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Train: {train_data.count()}\")\n",
        "print(f\"Test: {test_data.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbE1GqS_3-_s",
        "outputId": "2054a1ca-62c6-49fb-acea-1aaa34b7f997"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 5698\n",
            "Test: 1345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"label\")"
      ],
      "metadata": {
        "id": "YlIy5hI57hf7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrm =lr.fit(train_data)"
      ],
      "metadata": {
        "id": "dR_lvZ_f7xIK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingSummary = lrm.summary"
      ],
      "metadata": {
        "id": "Qu06ykmc8NR4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lrm.transform(test_data)\n",
        "\n",
        "print(\"Result of prediction :\")\n",
        "predictions.select(\"prediction\", \"label\", \"probability\").show(5)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy of the Model : {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRGyYDV3AZM7",
        "outputId": "23c629d9-66d0-4726-e015-00aab1e6f645"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of prediction :\n",
            "+----------+-----+--------------------+\n",
            "|prediction|label|         probability|\n",
            "+----------+-----+--------------------+\n",
            "|       1.0|  0.0|[0.43998226671737...|\n",
            "|       1.0|  1.0|[0.38879493641823...|\n",
            "|       0.0|  0.0|[0.64019648497660...|\n",
            "|       0.0|  0.0|[0.58344828683453...|\n",
            "|       0.0|  1.0|[0.57250268816098...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "Accuracy of the Model : 80.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy in train dataset\n",
        "print(f\"Accuracy: {trainingSummary.accuracy:.2%}\")\n",
        "\n",
        "# Area Under ROC (càng gần 1 càng tốt)\n",
        "print(f\"Area Under ROC: {trainingSummary.areaUnderROC:.4f}\")\n",
        "\n",
        "# FPR: False Positive Rate, TPR: True Positive Rate\n",
        "print(\"ROC:\")\n",
        "trainingSummary.roc.show(5)\n",
        "\n",
        "# Objective History\n",
        "print(\"Objective History:\")\n",
        "for i, loss in enumerate(trainingSummary.objectiveHistory):\n",
        "    print(f\"Iteration {i}: {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5NMs3wHABGD",
        "outputId": "69dc7a6a-616b-4d7d-8023-c396473d516a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.84%\n",
            "Area Under ROC: 0.8430\n",
            "ROC:\n",
            "+--------------------+--------------------+\n",
            "|                 FPR|                 TPR|\n",
            "+--------------------+--------------------+\n",
            "|                 0.0|                 0.0|\n",
            "|                 0.0| 0.00333555703802535|\n",
            "|                 0.0|  0.0066711140760507|\n",
            "|2.381519409383186...|0.009339559706470981|\n",
            "|2.381519409383186...|0.012675116744496331|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "Objective History:\n",
            "Iteration 0: 0.5762485159619298\n",
            "Iteration 1: 0.5327361899350359\n",
            "Iteration 2: 0.45399520952730466\n",
            "Iteration 3: 0.4378860236276876\n",
            "Iteration 4: 0.4324420932275601\n",
            "Iteration 5: 0.4236087304550611\n",
            "Iteration 6: 0.42196237200370273\n",
            "Iteration 7: 0.4215173468459716\n",
            "Iteration 8: 0.42115565106767644\n",
            "Iteration 9: 0.420752534740688\n",
            "Iteration 10: 0.4203338204634572\n",
            "Iteration 11: 0.4194805358269721\n",
            "Iteration 12: 0.41867967494528674\n",
            "Iteration 13: 0.4178052349780378\n",
            "Iteration 14: 0.41758867515712506\n",
            "Iteration 15: 0.4175747438121861\n",
            "Iteration 16: 0.4175529015810935\n",
            "Iteration 17: 0.41755187915075853\n",
            "Iteration 18: 0.41754837572111136\n",
            "Iteration 19: 0.4175467674214909\n",
            "Iteration 20: 0.4175461641026075\n",
            "Iteration 21: 0.41754534766064044\n",
            "Iteration 22: 0.41754495500034866\n",
            "Iteration 23: 0.41754437266426325\n",
            "Iteration 24: 0.4175435125825714\n",
            "Iteration 25: 0.4175426642421443\n",
            "Iteration 26: 0.4175425193155379\n",
            "Iteration 27: 0.41754245917681787\n",
            "Iteration 28: 0.41754245277874386\n",
            "Iteration 29: 0.41754245013628066\n",
            "Iteration 30: 0.4175424493258922\n",
            "Iteration 31: 0.41754244869228013\n",
            "Iteration 32: 0.41754244845565275\n",
            "Iteration 33: 0.4175424482398385\n",
            "Iteration 34: 0.4175424480959899\n",
            "Iteration 35: 0.4175424479747375\n",
            "Iteration 36: 0.41754244784665195\n",
            "Iteration 37: 0.41754244774246574\n",
            "Iteration 38: 0.41754244772740984\n",
            "Iteration 39: 0.4175424477269699\n",
            "Iteration 40: 0.41754244772560384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "predictions.groupby('label', 'prediction').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdiwBw9gBlWK",
        "outputId": "cc58a902-b137-462d-8daf-443ada33d024"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|  197|\n",
            "|  0.0|       1.0|   86|\n",
            "|  1.0|       0.0|  173|\n",
            "|  0.0|       0.0|  889|\n",
            "+-----+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eXxzh4qWer7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "\n",
        "predictions.select(\n",
        "    \"label\",\n",
        "    vector_to_array(col(\"probability\"))[1].alias(\"p_churn\"),\n",
        "    \"prediction\"\n",
        ").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O8i7SLreQZ8",
        "outputId": "a5f35f5a-3b24-43fb-9177-9112ef620500"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------------+----------+\n",
            "|label|            p_churn|prediction|\n",
            "+-----+-------------------+----------+\n",
            "|  0.0| 0.5600177332826282|       1.0|\n",
            "|  1.0| 0.6112050635817676|       1.0|\n",
            "|  0.0| 0.3598035150233997|       0.0|\n",
            "|  0.0| 0.4165517131654668|       0.0|\n",
            "|  1.0|0.42749731183901685|       0.0|\n",
            "|  0.0|0.39763718747605514|       0.0|\n",
            "|  0.0|0.41757401604325595|       0.0|\n",
            "|  1.0|0.47864305129600904|       0.0|\n",
            "|  0.0| 0.4060120442174221|       0.0|\n",
            "|  1.0| 0.4027194709300088|       0.0|\n",
            "+-----+-------------------+----------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "tp = predictions.filter(\n",
        "    (col(\"label\") == 1) & (col(\"prediction\") == 1)\n",
        ").count()\n",
        "\n",
        "fn = predictions.filter(\n",
        "    (col(\"label\") == 1) & (col(\"prediction\") == 0)\n",
        ").count()\n",
        "\n",
        "churn_recall_05 = tp / (tp + fn)\n",
        "\n",
        "print(f\"Churn Recall @ threshold=0.5: {churn_recall_05:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljirZpP6e7-U",
        "outputId": "be35b2be-4f42-4830-e2c0-02cf14644ced"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Churn Recall @ threshold=0.5: 53.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change threshold\n"
      ],
      "metadata": {
        "id": "WkXe9JuWfCWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, col\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "\n",
        "THRESHOLD = 0.3\n",
        "\n",
        "predictions_threshold = predictions.withColumn(\n",
        "    \"custom_prediction\",\n",
        "    when(vector_to_array(col(\"probability\"))[1] >= THRESHOLD, 1).otherwise(0)\n",
        ")\n"
      ],
      "metadata": {
        "id": "pAWSr76HfFWF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Confusion Matrix @ threshold = {THRESHOLD}\")\n",
        "predictions_threshold.groupby(\"label\", \"custom_prediction\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LL19UypfW5t",
        "outputId": "41597d4a-c2f2-4e5e-e180-144d35916101"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix @ threshold = 0.3\n",
            "+-----+-----------------+-----+\n",
            "|label|custom_prediction|count|\n",
            "+-----+-----------------+-----+\n",
            "|  1.0|                0|   87|\n",
            "|  0.0|                0|  764|\n",
            "|  0.0|                1|  211|\n",
            "|  1.0|                1|  283|\n",
            "+-----+-----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tp_new = predictions_threshold.filter(\n",
        "    (col(\"label\") == 1) & (col(\"custom_prediction\") == 1)\n",
        ").count()\n",
        "\n",
        "fn_new = predictions_threshold.filter(\n",
        "    (col(\"label\") == 1) & (col(\"custom_prediction\") == 0)\n",
        ").count()\n",
        "\n",
        "churn_recall_03 = tp_new / (tp_new + fn_new)\n",
        "\n",
        "print(f\"Churn Recall @ threshold={THRESHOLD}: {churn_recall_03:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr0oUxGKf45b",
        "outputId": "fa492cdb-07e7-4f4c-9aae-f5ccf6eb7d3a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Churn Recall @ threshold=0.3: 76.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare Threshold\n"
      ],
      "metadata": {
        "id": "rHY57EDQgRc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Threshold Comparison ===\")\n",
        "print(f\"Recall churn @ 0.5 : {churn_recall_05:.2%}\")\n",
        "print(f\"Recall churn @ 0.3 : {churn_recall_03:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x_QtcE7gREr",
        "outputId": "5428c37c-656a-48e4-824c-0379ea2121ef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Threshold Comparison ===\n",
            "Recall churn @ 0.5 : 53.24%\n",
            "Recall churn @ 0.3 : 76.49%\n"
          ]
        }
      ]
    }
  ]
}